{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4de9a3e-ceb8-4e89-a9b4-168197ee9d05",
   "metadata": {},
   "source": [
    "### Modeling Setup \n",
    "\n",
    "Goal: Build and compare multiple classification models to predict track popularity levels based on key audio features.\n",
    "\n",
    "Algorithms Implemented: \n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier  \n",
    "- Logistic Regression  \n",
    "- Bagging Classifier  \n",
    "\n",
    "Evaluation Metrics:  \n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1 Score (macro)  \n",
    "- Confusion Matrix  \n",
    "\n",
    "Final Criteria: \n",
    "The best model was chosen based on a balance between predictive performance (F1 score), robustness to noise, generalization to test data, and scalability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1fb21562-25c4-42da-b897-dc2466a1d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "73e301e4-79ab-410e-b724-61a1b9719ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\").squeeze()\n",
    "y_test = pd.read_csv(\"y_test.csv\").squeeze()\n",
    "\n",
    "scaler = joblib.load(\"scaler.joblib\")\n",
    "label_encoder = joblib.load(\"label_encoder.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "366b4e2a-bfd5-40d3-9359-91f232cd52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_encode = ['track_genre', 'loudness_binned']\n",
    "cols_present = [col for col in cols_to_encode if col in X_train.columns]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=cols_present, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=cols_present, drop_first=True)\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "24ce62cd-0fa3-45ba-9684-a4ff11d00dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Decision Tree (Gini) ---\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       1.00      1.00      1.00        53\n",
      "           2       1.00      1.00      1.00       172\n",
      "\n",
      "    accuracy                           1.00       313\n",
      "   macro avg       1.00      1.00      1.00       313\n",
      "weighted avg       1.00      1.00      1.00       313\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 88   0   0]\n",
      " [  0  53   0]\n",
      " [  0   0 172]]\n",
      "--- Decision Tree (Entropy) ---\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       1.00      1.00      1.00        53\n",
      "           2       1.00      1.00      1.00       172\n",
      "\n",
      "    accuracy                           1.00       313\n",
      "   macro avg       1.00      1.00      1.00       313\n",
      "weighted avg       1.00      1.00      1.00       313\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 88   0   0]\n",
      " [  0  53   0]\n",
      " [  0   0 172]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (Gini)\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "dt_gini.fit(X_train, y_train)\n",
    "y_pred_dt_gini = dt_gini.predict(X_test)\n",
    "print(\"--- Decision Tree (Gini) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt_gini))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt_gini))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt_gini))\n",
    "\n",
    "# Decision Tree (Entropy)\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "y_pred_dt_entropy = dt_entropy.predict(X_test)\n",
    "print(\"--- Decision Tree (Entropy) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt_entropy))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_dt_entropy))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt_entropy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1296d53c-e38a-4319-95a4-d6ef15c56401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV Mean F1: 0.9866089876399986\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       1.00      1.00      1.00        53\n",
      "           2       1.00      1.00      1.00       172\n",
      "\n",
      "    accuracy                           1.00       313\n",
      "   macro avg       1.00      1.00      1.00       313\n",
      "weighted avg       1.00      1.00      1.00       313\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 88   0   0]\n",
      " [  0  53   0]\n",
      " [  0   0 172]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Random Forest CV Mean F1:\", scores.mean())\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "74491aeb-2c26-4239-b235-b63d50938eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV Mean F1: 0.9702171946057202\n",
      "Accuracy: 0.987220447284345\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        88\n",
      "           1       0.98      0.98      0.98        53\n",
      "           2       0.99      0.99      0.99       172\n",
      "\n",
      "    accuracy                           0.99       313\n",
      "   macro avg       0.99      0.99      0.99       313\n",
      "weighted avg       0.99      0.99      0.99       313\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 87   0   1]\n",
      " [  0  52   1]\n",
      " [  1   1 170]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "scores = cross_val_score(lr, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Logistic Regression CV Mean F1:\", scores.mean())\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b6bfef8e-fada-4d0e-99d0-016754cc3451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AdaBoost Classifier ---\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       1.00      1.00      1.00        53\n",
      "           2       1.00      1.00      1.00       172\n",
      "\n",
      "    accuracy                           1.00       313\n",
      "   macro avg       1.00      1.00      1.00       313\n",
      "weighted avg       1.00      1.00      1.00       313\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 88   0   0]\n",
      " [  0  53   0]\n",
      " [  0   0 172]]\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier ---\n",
    "adaboost = AdaBoostClassifier(random_state=42)\n",
    "adaboost.fit(X_train, y_train)\n",
    "y_pred_adaboost = adaboost.predict(X_test)\n",
    "print(\"--- AdaBoost Classifier ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_adaboost))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_adaboost))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_adaboost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "97f9b092-c396-46d6-80d1-fbde73c5b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier CV Mean F1: 1.0\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       1.00      1.00      1.00        53\n",
      "           2       1.00      1.00      1.00       172\n",
      "\n",
      "    accuracy                           1.00       313\n",
      "   macro avg       1.00      1.00      1.00       313\n",
      "weighted avg       1.00      1.00      1.00       313\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 88   0   0]\n",
      " [  0  53   0]\n",
      " [  0   0 172]]\n"
     ]
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "\n",
    "bagging = BaggingClassifier(random_state=42)\n",
    "scores = cross_val_score(bagging, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "print(\"Bagging Classifier CV Mean F1:\", scores.mean())\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6fcda7f5-0248-4be1-8124-f79bd6e3d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results (F1 Macro Score):\n",
      "                          mean_f1    std_f1\n",
      "Decision Tree (Gini)     1.000000  0.000000\n",
      "Decision Tree (Entropy)  1.000000  0.000000\n",
      "Random Forest            0.986609  0.006340\n",
      "Logistic Regression      0.970217  0.009966\n",
      "Bagging Classifier       1.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "cv_results = {}\n",
    "models = {\n",
    "    \"Decision Tree (Gini)\": dt_gini,\n",
    "    \"Decision Tree (Entropy)\": dt_entropy,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Logistic Regression\": lr,\n",
    "    \"Bagging Classifier\": bagging\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    cv_results[name] = {\n",
    "        \"mean_f1\": scores.mean(),\n",
    "        \"std_f1\": scores.std()\n",
    "    }\n",
    "\n",
    "print(\"\\nCross-Validation Results (F1 Macro Score):\")\n",
    "print(pd.DataFrame(cv_results).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0217b2a2-61f0-4902-b9a0-a78a3a7b7991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation - Bagging Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00        88\n",
      "         Low       1.00      1.00      1.00        53\n",
      "      Medium       1.00      1.00      1.00       172\n",
      "\n",
      "    accuracy                           1.00       313\n",
      "   macro avg       1.00      1.00      1.00       313\n",
      "weighted avg       1.00      1.00      1.00       313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Evaluation - Bagging Classifier\")\n",
    "final_bagging_preds = bagging.predict(X_test)\n",
    "print(classification_report(y_test, final_bagging_preds, target_names=label_encoder.inverse_transform([0, 1, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8a2b6-bf39-4165-b3c0-c766f3281fcc",
   "metadata": {},
   "source": [
    "### Final Model Conclusion\n",
    "\n",
    "After running multiple classification models, the **Bagging Classifier** proved to be the most effective option for predicting track popularity. It outperformed other models in terms of F1 macro score and generalization on the test set. Bagging demonstrated strong resilience to noise and delivered more consistent performance across cross-validation folds. Its ability to reduce variance and improve model stability made it particularly suited for a dataset with a variety of audio features and genre variability.\n",
    "\n",
    "This is especially helpful in the context of **Spotify track prediction**, where musical attributes like danceability, loudness, and instrumentalness can vary widely across tracks and genres. The Bagging approach allows Spotify to make more reliable predictions about which tracks are likely to become popular—even when some features may be noisy or less predictive on their own.\n",
    "\n",
    "The **Random Forest model** came in a close second, performing well in both accuracy and F1 score. However, it was slightly more sensitive to less informative features, which may limit its robustness when applied to broader Spotify datasets. While still strong, it lacked the overall stability and consistency of the Bagging model, making it a less ideal choice in this specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa93ffa-0ca4-4e51-80ca-527ef7291481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
